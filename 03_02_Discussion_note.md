# ğŸŒ‹ 3rd meeting : Natural Language Processing with Disaster Tweets 

**written by Soyoun Son**         
**Date : 050922**

#### ğŸ¦† Kaggle : https://www.kaggle.com/c/nlp-getting-started

## ğŸŒ± í’€ììŠ¤ì¿¨ (5ì›” 9ì¼) 

ì„œë¡œ ê°™ì´ ë…¼ì˜ëœ ë¶€ë¶„ ë° ê³µë¶€í•œ ê²ƒì— ëŒ€í•´ì„œ ì ìŒ

### â˜ºï¸ attention 
: ë””ì½”ë”ì—ì„œ ì¶œë ¥ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë§¤ ì‹œì ë§ˆë‹¤ ì¸ì½”ë”ì—ì„œì˜ ì „ì²´ì…ë ¥ ë¬¸ì¥ì„ ë‹¤ì‹œ í•œë²ˆ ì°¸ê³ .
- dot production attention 
- bert-> transformer-> attention 

<img src="/images/attention.png" width="500">
ref fig : https://github.com/jadore801120/attention-is-all-you-need-pytorch


ëŒ€ë¶€ë¶„ì˜ ë¬¸ì œë¥¼ í‘¸ëŠ”ë°, electra ë˜ëŠ” bertì„ 
Bert-using-TFHUB.ipynb

### â˜ºï¸ Bert
ref: https://wikidocs.net/115055

- googleì´ ê³µê°œí•œ ì‚¬ì „í›ˆë ¨ëœ ëª¨ë¸ 
- 33ì–µê°œë¡œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ 
- input 
   + subword tokenizer : wordpieceë¼ëŠ” í† í¬ë‚˜ì´ì € ì‚¬ìš©í•¨ 
   + positional embedding : ë‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒ (ë‹¨ì–´ì˜ ìœ„ì¹˜ë¥¼ ì•Œìˆ˜ ì—†ìœ¼ë¯€ë¡œ) 
   + attention mask  
  : ì´ 3ê°œê°€ í•©ì³ì ¸ì„œ bertì˜ inputìœ¼ë¡œ ë“¤ì–´ê° 
- bert structure 
   + multihead self attention : 512ê°€ ë§¥ìŠ¤
     (self-attention : ë‹¨ì–´ ìœ ì‚¬ë„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŒ)
     https://wikidocs.net/89786
         
   + rasidual connection  
   + normalization 
   + feed forward NN 

- Bert train 
  + MLM
  + NSP : ë¬¸ì¥ë¶„ë¥˜, binary classification 

ref : https://www.kaggle.com/code/wrrosa/keras-bert-using-tfhub-modified-train-data


### â˜ºï¸ Ensemble 
ensemble ì˜ ê²½ìš° TF-IDFë¥¼ ì´ìš©í•œ í›„ ì‚¬ìš©í•¨ 




---------------
encodingì€ ì¤„ì´ëŠ” ê²ƒì´ê³ , GPTë§ê³  êµ¬ê¸€ì´ ë‚´ë†“ì€ ê²ƒì´ PaLM (ì¤„ì´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë©”ëª¨ë¦¬ë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒ)
+ google : PaLM
http://aidev.co.kr/chatbotdeeplearning/11284
https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html

+ meta : OPT 

+ Alpha code : https://towardsdatascience.com/deepminds-alphacode-explained-everything-you-need-to-know-5a86a15e1ab4


embedded : 800K
domain : 


ê°œë°œì ìœ¼ë¡œë³´ë©´ (í”„ë¡œê·¸ë¨ì•ˆì—ì„œì˜) ì•„í‚¤í…ì³ ë°”ê¾¼ë‹¤ê³  ì„±ëŠ¥ì´ ì¢‹ì•„ì§„ë‹¤ê³  ë³¼ìˆ˜ ì—†ë‹¤. -> ìœ ì§€/ë³´ìˆ˜
(ì‹œìŠ¤í…œì•ˆì—ì„œì˜) ì•„í‚¤í…ì³ëŠ” ì„±ëŠ¥ì´ ê°œì„  ê°€ëŠ¥  
ìµœì í™”ëŠ” ë²„ë¦°ë‹¤ëŠ” ê²ƒì˜ ì˜ë¯¸


-----------------
ML ê°œë…? 
call back function : ë„ì¤‘ì— ëŠì„ìˆ˜ê°€ ì—†ìœ¼ë‹ˆê¹, listenerê°™ì€ ê²ƒ  
+ early stopping
+ ModelCheckpoint
+ ReduceLROnPlateau
+ csvLogger




Solve NLP proble, with deep learning : https://www.kaggle.com/code/megr25/twitter-nlp-feature-engineer-deep-learning

