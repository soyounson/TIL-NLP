# ğŸ¦– Quora Question Pairs (QQP)

**written by Soyoun Son**         
**Date : 051722**


#### ğŸ¦† Kaggle ref : https://www.kaggle.com/c/quora-question-pairs

## ğŸŒ± í’€ììŠ¤ì¿¨ (5ì›” 17ì¼ 2022ë…„, ëª¨ë‘ì—°êµ¬ì†Œ ìº í¼ìŠ¤) 


## ğŸ»â€â„ï¸ ë°œí‘œ 1 
- baseline training ì´í›„ ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•´ì„œ EDA ì‘ì—… ì§„í–‰ 
- **[lime](https://github.com/marcotcr/lime) library : DLì—ì„œ ì œëŒ€ë¡œ í•™ìŠµí•˜ê³  ìˆëŠ”ì§€ë¥¼ NLPì— ì ìš©í•¨ **
(ref: https://c3.ai/glossary/data-science/lime-local-interpretable-model-agnostic-explanations/) 
(ref2 : https://christophm.github.io/interpretable-ml-book/lime.html)
 
## ğŸ»â€â„ï¸ ë°œí‘œ 2 
### â˜ºï¸ ë‹¨ì–´í‘œí˜„
ì½”í¼ìŠ¤ êµ¬ì„±í•˜ê³  id ì£¼ëŠ” ê²ƒ 
### í†µê³„ê¸°ë°˜ ê¸°ë²• : ë‹¨ì–´ ë¹ˆë„ìˆ˜ì— ë”°ë¼ ë²¡í„°ë¡œ í‘œí˜„ TF-IDF, ì½”ì‚¬ì¸ ìœ ì‚¬ë„, 
ì ë³„ìƒí˜¸ì •ë³´ëŸ‰ (pointwise mutual information) 
### ì¶”ë¡ ê¸°ë°˜ê¸°ë²• : ë¶„í¬ê°€ì„¤ì— ê¸°ì´ˆë¥¼ í•˜ì§€ë§Œ ë¬¸ì¥ë‚´ì—ì„œ ì§€ì—½ì ì¸ ì˜ì—­, CBOW, skip-gram-> ë‘ê°œ ë¬¶ì–´ì„œ word2vec

- CBOW 
- word2vec : ë§ë­‰ì¹˜ê³„ìˆ˜ê°€ ë§ì•„ì§€ë©´ ë³µì¡ë„ê°€ ì»¤ì§ -> ì†ë„ê°œì„  ë°©ë²•ìœ¼ë¡œ embedding, negative sampling (sigmoid fnì´ìš©í•´ì„œ ì´ì§„ë¶„ë¥˜) 

### â˜ºï¸ [GloVe : Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)
í†µê³„ê¸°ë°˜í‘œí˜„ë°©ì‹ + ì˜ë¯¸ì¶”ë¡  
extract global corpus statistics information
ë™ì‹œë°œìƒí™•ë¥ ì— ëŒ€í•œ ë¹„ìœ¨ì„ êµ¬í•˜ëŠ” ê²ƒì´ ë” ì¤‘ìš”í•¨ì„ ë‚˜íƒ€ëƒ„. ë¹„ìœ¨ì— ë”°ë¼ì„œ ì¸ì§€í–ˆì„ë•Œ ì¢€ ë” ê°€ì‹œì ìœ¼ë¡œ ë‚˜íƒ€ë‚´ê¸° ë•Œë¬¸ì„ 
ì„ë² ë”©ëœ ì¤‘ì‹¬ë‹¨ì–´ì™€ ì£¼ë³€ë‹¨ì–´ ë²¡í„°ì˜ ë‚´ì ì´ ì „ì²´ ì½”í¼ìŠ¤ì—ì„œì˜ ë™ì‹œ ë“±ì¥í™•ë¥ ì´ ë˜ë„ë¡ ë§Œë“œëŠ” ê²ƒ 
ì •ë³´ëŸ‰ì— ë”°ë¼ì„œ ê°€ì¤‘ì¹˜ë¥¼ ì¤Œ 

### â˜ºï¸ embedding layer 
ì´ì‚°ì ì¸ ê°’ë“±ì„ ìˆ˜ì¹˜ì ì¸ ê°’ìœ¼ë¡œ ë§µí•‘ì‹œí‚¤ëŠ” ê²ƒ 
https://www.kaggle.com/code/rajmehra03/a-detailed-explanation-of-keras-embedding-layer/notebook
[next sentend prediction, NSP](https://towardsdatascience.com/bert-for-next-sentence-prediction-466b67f8226f)

### Bert ì™€ ë‹¨ì–´ ì„ë² ë”© 
#### input representation 
- token embedding 
- segment embedding 
- position embedding 
-> ëª¨ë‘ ê°€ì¤‘ì¹˜ ë²¡í„°ë¥¼ ê°–ê³ ì™€ì„œ ê³„ì‚° 

#### ë‚´ë¶€ì½”ë“œ
tf.gradients()ë¡œ í•™ìŠµ 


## ğŸ»â€â„ï¸ ë°œí‘œ, [NLP ë¬¸ì œí•´ê²°ì „ëµ](https://www.notion.so/modulabs/NLP-bdc7562bc0e146c69cbf55cf9590dcf7)
#### process 
understand problem -> EDA -> baseline models -> improve performance 

### ìì—°ì–´ ì²˜ë¦¬ ë¬¸ì œ
- ë¬¸ì¥ì„ ì´í•´í•˜ë©´ í’€ìˆ˜ìˆëŠ” ë¬¸ì œë“¤ì´ ìƒë‹¹ìˆ˜ë¥¼ ì°¨ì§€í•¨. ê·¸ë˜ì„œ ì´ê²ƒì¸ì§€ë¥¼ í™•ì¸í•˜ê³  ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ ê°. 
- ìˆ˜ì¹˜í™”ë¡œ ë‚˜íƒ€ë‚´ì•¼í•¨
- ë¬¸ì¥ì„ ì´í•´í•˜ë©´ í’€ìˆ˜ìˆëŠ” ë¬¸ì œë“¤ì´ ìƒë‹¹ìˆ˜ë¥¼ ì°¨ì§€í•¨. ê·¸ë˜ì„œ ì´ê²ƒì¸ì§€ë¥¼ í™•ì¸í•˜ê³  ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ ê°. ë‚˜
- ë¬¸ì¥ì„ ì´í•´í•˜ë©´ í’€ìˆ˜ìˆëŠ” ë¬¸ì œë“¤ì´ ìƒë‹¹ìˆ˜ë¥¼ ì°¨ì§€í•¨. ê·¸ë˜ì„œ ì´ê²ƒì¸ì§€ë¥¼ í™•ì¸í•˜ê³  ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ ê°. 
- ê·¸ë¦¬ê³  ë‚˜ì„œ ë² ì´ìŠ¤ë¼ì¸ëŒ€ë¹„ ì–´ë–¤ì‹ìœ¼ë¡œ ìµœì í™” í• ê²ƒì¸ì§€ ìƒê°í•´ ë³¼ ê²ƒ 
- ìµœì í™”ëŠ” ëŒ€ì²´ì ìœ¼ë¡œ íŒ¨í„´ì´ ìˆìŒ. 
- out of the box (creative) ì¸ ê²½ìš°ëŠ” ë…¼ë¬¸ì„ ì‘ì„±í•˜ëŠ” ê²ƒ (1ë…„ì´ìƒ ì‹œê°„ì†Œìš”) ë”°ë¼ì„œ ìºê¸€ê³¼ëŠ” ê±°ë¦¬ê°€ ìˆìŒ. 
- NLU : ê¸€ë£¨ì— 8ê°œ ìŠˆí¼ê¸€ë£¨ì— 9ê°œ? ì´ëŸ°ì‹ìœ¼ë¡œ?
 - [wikidata](https://www.wikidata.org/wiki/Wikidata:Main_Page) : ëª¨ë“  ë‹¨ì–´ë“¤ì„ ì •í˜•í™” ì‹œì¼œë†“ìŒ 
- NLG : ë²ˆì—­, ë¬¸ì¥ì„ ë§Œë“¤ì–´ ë‚´ëŠ” ê²ƒ 
  - QQP : ìœ ì‚¬ë„ì˜ˆì¸¡ ë¬¸ì œì— í•´ë‹¹í•¨ 

- [papers w/ code](https://paperswithcode.com/)
#### GLUE 
9ê°œì˜ ìœ í˜•ìœ¼ë¡œ ë§Œë“¤ì–´ ë†“ìŒ 
#### Super GLUE
- ê¸°ì—…ë“¤ì´ í•¨ê»˜ ë§Œë“  ê²ƒ. 8ê°œì˜ ìœ í˜•ìœ¼ë¡œ ë§Œë“¤ì–´ ë†“ìŒ 
- êµ¬ë¶„ì€ ë°ì´í„°ì…‹ì˜ ì¶œì²˜, í¬ê¸°, ë¼ë²¨ë“±ì— ë”°ë¼ì„œ ë˜ì–´ ìˆìŒ

### ìì—°ì–´ì˜ ê²½ìš°
1. ì§€ì‹ì´ìš© -> domain knowledgeê°€ í•„ìš”
2. ì˜ë¯¸ì´í•´ì´ìš© 
3. ì„ë² ë”© ìˆ˜ì¤€ : ë¬¸ìê°€ ë“¤ì–´ì˜¤ë©´ ê·¸ê²ƒì´ ë²¡í„°ê°€ ë˜ëŠ” ê³¼ì •ì´ë‚˜ ê²°ê³¼ë¬¼ 
  (ë‹¨ì–´-> ë¬¸ì¥ -> ë¬¸ì„œ), pretrained modelì—ì„œ bertê°€ ë‚˜ì˜´ 
4.  










