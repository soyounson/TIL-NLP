## Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide marker Discovery (2017)

### :seedling: Background 
#### :leaves: GAN (Generative Adversarial Network)
- ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¤‘ ì´ë¯¸ì§€ ìƒì„±ì— ë„ë¦¬ ì“°ì´ëŠ” ëª¨ë¸ì´ë‹¤. ê¸°ë³¸ì ì¸ ë”¥ëŸ¬ë‹ ëª¨ë¸ CNN (Convolutional NEural NEtwork)ê³¼ ë¹„êµí•˜ë©´, CNNì€ ì´ë¯¸ì§€ ë¶„ë¥˜ (image classification)ì— ì“°ì´ëŠ”ë° ë°˜í•´ GANì€ ë°ì´í„°ì…‹ê³¼ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ë§Œë“œëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•œë‹¤. 
- Generator (ìƒì„±ì)ì™€ (íŒë³„ì), ë‘ê°œì˜ ëª¨ë¸ì´ ë™ì‹œì— ì ëŒ€ì ì¸ ê³¼ì •ìœ¼ë¡œ í•™ìŠµí•œë‹¤. ì¦‰, ìƒì„±ìëŠ” ì‹¤ì œ ë°ì´í„° ë¶„í¬ë¥¼ í•™ìŠµí•˜ê³ , íŒë³„ìëŠ” ì›ë˜ì˜ ë°ì´í„°ì¸ì§€ ìƒì„±ìë¡œë¶€í„° ìƒì„±ëœ ê²ƒì¸ì§€ êµ¬ë¶„í•œë‹¤. ìƒì„±ìì˜ í•™ìŠµê³¼ì •ì€ ì´ë¯¸ì§€ë¥¼ ì˜ ìƒì„±í•´ì„œ ì†ì¼ í™•ë¥ ì„ ë†’ì´ê³ , íŒë³„ìëŠ” ì œëŒ€ë¡œ êµ¬ë¶„í•˜ëŠ” í™•ë¥ ì„ ë†’ì´ëŠ” ë‘ í”Œë ˆì´ì–´ì˜ ë°˜ë³µë˜ëŠ” minmax game ê³¼ì •ì´ë‹¤. 
(ref : https://ysbsb.github.io/gan/2020/06/17/GAN-newbie-guide.html)
- DëŠ” ì „ì²µì ì¸ ì‹ì„ í¬ê²Œ ë§Œë“œëŠ” ë°©í–¥ìœ¼ë¡œ íŒŒë¼ë¯¸í„°ë¥¼ í•™ìŠµ, D(x)ëŠ” í¬ê²Œ ë§Œë“¤ì–´ì•¼ ì¢‹ê³ , D(G(z))ëŠ” ì‘ê²Œ ë§Œë“¤ì–´ì•¼ ì¢‹ë‹¤. (ref : https://wingnim.tistory.com/49)
- ìƒì„±ëŒ€ë¦½ ì‹ ê²½ë§/ìƒì„±ì  ì ëŒ€ ì‹ ê²½ë§ì€ ë¯¸ë¶„ ê°€ëŠ¥ ìƒì„±ìì— ê¸°ì´ˆí•œ ë˜ ë‹¤ë¥¸ ìƒì„± ëª¨í˜•í™” ì ‘ê·¼ ë°©ì‹ì´ë‹¤. 
- ìƒì„±ìë§ì€ í‘œë³¸ x = g(z; Î¸<sup>(g)</sup>) ë“¤ì„ ì§ì ‘ ìƒì„±í•œë‹¤. ë°˜ë©´, ëŒ€ë¦½ìì¸ íŒë³„ì ë§ì€ í›ˆë ¨ì§‘í•©ì—ì„œ ë½‘ì€ í‘œë³¸ê³¼ ìƒì„±í•œ í‘œë³¸ì„ êµ¬ë¶„í•˜ë ¤ í•œë‹¤. íŒë³„ìë§ì€ í•˜ë‚˜ì˜ í™•ë¥ ê°’ d(x; Î¸<sup>(d)</sup>)ì„ ì‚°ì¶œí•˜ëŠ”ë°, ì´ í™•ë¥ ê°’ì€ xê°€ ëª¨í˜•ì—ì„œ ë½‘ì€ ê°€ì§œ í‘œë³¸ì´ ì•„ë‹ˆë¼ ì§„ì§œ í›ˆë ¨ ê²¬ë³¸ì¼ í™•ë¥ ì„ ë‚˜íƒ€ë‚¸ë‹¤. ìƒì„± ëŒ€ë¦½ ì‹ ê²½ë§ì˜ í•™ìŠµ ê³¼ì •ì€ ì˜í•©ê²Œì„ (zero-sum game)ì˜ ê´€ì ì—ì„œ ì„¤ëª…í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì‰½ë‹¤. ì˜í•©ê²Œì„ì—ì„œ í•¨ìˆ˜ v(Î¸<sup>(g)</sup>, Î¸<sup>(d)</sup>)ëŠ” íŒë³„ìê°€ ë°›ëŠ” ë³´ìƒì„ ê²°ì •í•˜ê³ , ìƒì„±ìëŠ” ê·¸ê²ƒì˜ ë¶€ì •ì¸ -v(Î¸<sup>(g)</sup>, Î¸<sup>(d)</sup>)ë¥¼ ë³´ìƒìœ¼ë¡œ ë°›ëŠ”ë‹¤. 
- ìˆ˜ë ´ì‹œ ìƒì„±ìì˜ í‘œë³¸ì€ ì‹¤ì œ ìë£Œì™€ êµ¬ë¶„í•  ìˆ˜ ì—†ì„ ì •ë„ì´ë©°, íŒë³„ìëŠ” ëª¨ë“  ì ì—ì„œ 1/2ì˜ í™•ë¥ ì„ ì¶œë ¥í•œë‹¤. ê·¸ëŸ¬ë©´ íŒë³„ìë¥¼ íê¸°í•´ë„ ëœë‹¤. 
(ref : Ian Goodfellow, Yoshua Bengio, Aaron Courville, Deep learning (2015))

- Generatorê°€ í•˜ëŠ” ì¼ì€ training ë°ì´í„°ì™€ ìœ ì‚¬í•œ 'ê°€ì§œ' ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒì…ë‹ˆë‹¤. Discriminatorê°€ í•˜ëŠ” ì¼ì€ ì´ë¯¸ì§€ë¥¼ ë³¸ ë’¤, ì‹¤ì œ training ë°ì´í„°ì¸ì§€ generatorë¡œë¶€í„° ìƒì„±ëœ ê°€ì§œ ì´ë¯¸ì§€ì¸ì§€ë¥¼ ì¶œë ¥í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. íŠ¸ë ˆì´ë‹ ë™ì•ˆ, generatorëŠ” ëŠì„ì—†ì´ ë” ë‚˜ì€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ disciminatorë¥¼ ëŠ¥ê°€í•˜ë ¤ ë…¸ë ¥í•˜ëŠ” ë°˜ë©´, discriminatorëŠ” ì§„ì§œ ì´ë¯¸ì§€ì™€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ë” ì˜ ê°ì§€í•˜ê³  ë¶„ë¥˜í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•©ë‹ˆë‹¤. ì´ ê²Œì„ì˜ ê· í˜•ì€ generatorê°€ training ë°ì´í„°ì—ì„œ êº¼ë‚´ì˜¨ ë“¯í•œ ì™„ë²½í•œ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ ë‚´ê³  ìˆì„ ë•Œì´ê³ , discriminatorëŠ” í•­ìƒ generatorì˜ ê²°ê³¼ê°€ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ 50%ì˜ ì‹ ë¢°ë„ë¥¼ ê°€ì§€ê³  ì¶”ì¸¡í•˜ë„ë¡ ë‘”ë‹¤. Discriminatorë¥¼ ì‹œì‘ìœ¼ë¡œ íŠœí† ë¦¬ì–¼ì„ ì‹œì‘í•  í…ë°, ëª‡ ê°€ì§€ í‘œê¸°ë²•ì„ ì •ì˜í•´ë´…ì‹œë‹¤. ì§€ê¸ˆë¶€í„° 'x'ë¥¼ ì´ë¯¸ì§€ë¥¼ ëŒ€í‘œí•˜ëŠ” ë°ì´í„°ë¼ê³  ë¶€ë¦…ì‹œë‹¤. D(x)ëŠ” xê°€ generatorê°€ ì•„ë‹Œ training ë°ì´í„°ì—ì„œ ë‚˜ì™”ì„ í™•ë¥ ì„ ì¶œë ¥í•˜ëŠ” discriminator ë„¤íŠ¸ì›Œí¬ì´ë‹¤. ìš°ë¦¬ëŠ” ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ë•Œë¬¸ì— D(x)ì— ëŒ€í•œ ì…ë ¥ì˜ í¬ê¸°(size)ëŠ” 3 * 64 * 64ì…ë‹ˆë‹¤. ì§ê´€ì ìœ¼ë¡œ D(x)ëŠ” xê°€ training ë°ì´í„°ì—ì„œ ë‚˜ì™”ì„ ë•Œ ë†’ê³ , generatorë¡œë¶€í„° ë§Œë“¤ì–´ì¡Œì„ ë•Œ ë‚®ë‹¤. D(x)ëŠ” ì „í†µì ì¸ ì´ì§„ ë¶„ë¥˜ê¸° (binary classifier)ë¡œ ìƒê°í•  ìˆ˜ ìˆë‹¤. Generatorë¥¼ ìœ„í•œ í‘œê¸°ë²•ìœ¼ë¡œëŠ”,  í‘œì¤€ì •ê·œë¶„í¬ë¡œë¶€í„° ì¶”ì¶œëœ ì ì¬ ê³µê°„(latent space) ë²¡í„°ë¥¼ 'z'ë¼ê³  í•˜ì. G(z)ëŠ” ì ì¬ ë²¡í„° zë¥¼ ë°ì´í„° ê³µê°„(data-space)ìœ¼ë¡œ ë§¤í•‘ì‹œì¼œì£¼ëŠ” generator í•¨ìˆ˜ì´ë‹¤. Gì˜ ëª©í‘œëŠ” training dataì˜ p_data ë¶„í¬ë¥¼ ì¶”ì •í•˜ì—¬, ê·¸ ì¶”ì • ë¶„í¬(p_g)ë¡œë¶€í„° ê°€ì§œ ìƒ˜í”Œì„ ìƒì„±í•˜ëŠ” ê²ƒì´ë‹¤. ë”°ë¼ì„œ, D(G(z))ëŠ” Generatorì˜ ì•„ì›ƒí’‹ì´ ì§„ì§œ ì´ë¯¸ì§€ì¼ í™•ë¥ ì„ ì˜ë¯¸í•œë‹¤. (* =ê°€ì§œ ì´ë¯¸ì§€ê°€ ì§„ì§œ ì´ë¯¸ì§€ë¡œ íŒë³„ë  í™•ë¥ ) Goodfellowì˜ ë…¼ë¬¸ì— ë¬˜ì‚¬ëœ ê²ƒì²˜ëŸ¼,  Dì™€ GëŠ” DëŠ” ì§„ì§œì™€ ê°€ì§œë¥¼ ì •í™•í•˜ê²Œ êµ¬ë¶„í•˜ëŠ” í™•ë¥ (log D(x))ì„ í‚¤ìš°ê¸° ìœ„í•´, GëŠ” Dê°€ Gì˜ ì•„ì›ƒí’‹ì„ ê°€ì§œë¡œ íŒë‹¨í•  í™•ë¥ (log(1-D(G(x)))ì„ ë‚®ì¶”ëŠ” minmax ê²Œì„ì„ í•œë‹¤. (ref. https://comlini8-8.tistory.com/7 )


#### :leaves: GAN (Generative Adversarial Network) models 
- GAN : íƒœì´ˆì˜ GANì€ FC layerì„ ì‚¬ìš©. generatorëŠ” CNNì„ ì‚¬ìš©í•´ì„œ ë§Œë“¦.
- DCGAN : pooling layer ì‚¬ìš©í•˜ì§€ ì•Šê³ , stride size = 2ë¡œ í•´ê²°í•¨. bath norm, adam ì‚¬ìš© 
(ref : https://wingnim.tistory.com/49)

> ê°€ì¥ ë¨¼ì € ì •ìƒ ë°ì´í„°ë“¤ë¡œ DCGANë¦‰ í•™ìŠµì‹œí‚¤ê³ , anomaly íŒë‹¨. P_zì—ì„œ zë¥¼ ë½‘ê³ , Zì˜ ê³„ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ê³¼ì •ì„ ì¼ì • ê±°ì¹œ ë‹¤ìŒ ì´ zë¡œë¶€í„° query data, xê°€ ë‹¤ì‹œ ë§Œë“¤ì–´ì§€ëŠ”ì§€ë¥¼ íŒë‹¨í•¨. ì¦‰, ì •ìƒ ë°ì´í„°ì˜ latent spaceë¡œ ì ì ˆí•˜ê²Œ ë§¤í•‘ë˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ í†µí•´ ë°ì´í„°ì˜ ì •ìƒ ì—¬ë¶€ë¥¼ íŒë‹¨. (ref : https://kangbk0120.github.io/articles/2018-01/ano-gan)

### :seedling: Prologue (ì •ë¦¬)
- background : ì˜í•™ìª½ ì´ë¯¸ì§€ ë°ì´í„°ì—ì„œ ì§„ë‹¨, ì§ˆë³‘ ì§„í–‰ ëª¨ë‹ˆí„°ë§ ë° ì§„í–‰ ë°˜ì‘ë“±ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ì‚¬ìš©.
- related work : anomaly detectionì´ë€ ì •ìƒì  ë°ì´í„°ì— fitë˜ì§€ ì•ŠëŠ” ê²ƒë“¤ì„ ë°œê²¬í•´ë‚´ëŠ” ê³¼ì •ì„. 
- unsupervised learningì„ ë² ì´ìŠ¤ë¡œ í•œ DCGANì„.
- ê±´ê°•í•œ ìƒíƒœì˜ ì´ë¯¸ì§€ë¥¼ ì´ìš©í•˜ì—¬ Discriminatorë¥¼ trainingì‹œí‚´.
- ê·¸ ë‹¤ìŒìœ¼ë¡œ, discriminatorë¥¼ í†µí•´ ê±´ê°•í•œ ë°ì´í„°ì™€ ì´ìƒì´ ìˆëŠ” ë°ì´í„°ì—ì„œ ì´ìƒ ì§„ë‹¨ì„ í•˜ë„ë¡ í•¨. 
- image spaceì—ì„œ latent spaceë¡œ ë§µí•‘ ì‹œí‚´

### :seedling: Abstract
- perform **unsupervised learning to identify anomalies in imaging data as candidates for markers**.
- propose **AnoGAN**, a deep convolutional generative adversarial network (DCGAN) to learn a minifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the **mapping from image space to a latent space**. 

### :seedling: Chap.1 Introduction 
#### :leaves: motivation 
- the detection and qualification of disease markers in imaging data is critical during diagnosis, and monitoring of disease progression, or treatment response.
- medical imaging enables the observation of markers correlating with disease status, and treatment response. 
- typically,computational detection in imaging data requires **extensive supervised training using large amounts of annotated data such as labeled lesions**
#### :leaves: related work
- anomaly detection is the task of **identifying test data not fitting the normal data distribution seen during training**.
- typically either use an explicit representation of the **distribution of normal data in a feature space, and determine outliers based on the local density** at the observations' position in the feature space. 
- Seebock et al identified anomalous regions in optical coherence tomography (OCT) images through unsuperviesd learning on healthy examples, using a **convolutional autoencoder and a one-class support vectror machine (SVM)**, and eplored different classes of anomalies. In contrast to this work, the SVM in Seebock's sutdy involved the need to choose a hyper-paramter that defined the amount of training points covered by the estimated healthy region. 
- RAdford et al. introduced deep convolutional generative adversarial networks (DCGANs) and showed that GANs are capacble of captureing semantic image content enabling vector arithmetic for visual concepts.
- Yeh et al. trained GANs on natural images and applied the trained model for semantic image inpainting. 

#### :leaves: distinction of this work
- define an anomaly score, which is not needed in an inpainting task. 
- the main difference of this paper to aforementioned anomaly detection work is the representative power of the generative model and the coupled mapping schema, which utilizes a trained DCGAN and **enable accurate discrimination between normal anatomy, and local anomalous appearance**. (:warning: how?)

### :seedling: Chap.2 Generative Adversarial Representation Learning to Identify Anomalies
:warning: Instead of a single cost function optimization, it aims at the Nash equilibrium of costs, increasing the representattive power and specificity of the generative model, while at the same time becoming more accurate in classifying real-from generated data and improving the corresponding feature mapping.

#### 2.1 Unsupervised manifold learning of normal anatomical variability
- setup : Mê°œê°€ ì„¸íŠ¸ì¸ ì˜í•™ ì´ë¯¸ì§€ <I<sub>m</sub>> (healthy anatomy, m = 1...M, size = a x b), ì—¬ê¸°ì„œ K 2D image patches <x<sub>k,m</sub>> (size = c x c) ë½‘ì•„ëƒ„.
- Train : GANì´ìš©í•´ì„œ manifold X í•™ìŠµ (healthy anatomyì¸ <I<sub>m</sub>> ì‚¬ìš©)
- Test : <y<sub>n</sub>,l<sub>n</sub>> ì—¬ê¸°ì„œ y<sub>n</sub> (size = c x c)ì€ unseen imageì´ê³ , l<sub>n</sub>ì€ an array of binary image-wise ground truth labels, ì¦‰ 0 í˜¹ì€ 1ì´ë¼ëŠ” ê°’ì„ ê°–ì€ arrayì„. 
- ì¦‰, testì˜ ê²½ìš°ëŠ” labelì¡´ì¬
**Encoding anatomical variability with a GANS** 
: GANì˜ êµ¬ì„± ë° D/Gì— ëŒ€í•œ ì„¤ëª…
- GAN : two adversarial modules, a generator G + a discriminator D
- G : learn a distribution p<sub>g</sub> over data x via a mapping G(z) of sample z, 1D vectors of uniformly distributed input noise sampled from latent space, Z, to 2D images in the image space manifold X, which is populated by healthy examples.
- G's architecture : convolutional decoder ì™€ ê°™ìŒ.
- D : a standard CNN that maps a 2D image to a single scalar value D(.)
- D/G are simultaneously optimized through the follwoing two-player minimax game with value function V(G,D)

#### 2.2 Mapping new Images to the Latent space
- GëŠ” mappingì„ ë°°ì›€ : G(z) = z â†’ x (latent space representations, z â†’ realistic (normal) image, x)
- the degeree of similarity of x and G(z) depends on to which extent the query image following the data distribution p<sub>g</sub> that was used for training of the generator
- define a loss function fot the mapping of new images to the latent space that comprises two components, a **residual loss** and a **discrimination loss**. 
  * **residual loss** enforces the visual similarity between the generated image G(Z<sub>Î³</sub>) and query image x
  * **discrimination loss** enforces the generated image G(Z<sub>Î³</sub>) to lie on the learned manifold X
- D and G are both utilized to adapt the coefficients of z via backpropagation. (ì—­ì „íŒŒí†µí•´ z ê³„ìˆ˜ ì ì‘ì‹œí‚¤ëŠ”ë° ì‚¬ìš©ë¨.)

**Residual loss**
L<sub>R</sub>(Z<sub>Î³</sub>) = Î£ |x-G(Z<sub>Î³</sub>)|

**An improved discrimination loss based on feature matching** (ê¸°ì¡´ ë…¼ë¬¸ê³¼ì˜ ì°¨ë³„ì„±)
- ê¸°ì¡´ì— Dë¥¼ ì†ì´ê¸° ìœ„í•´ Z<sub>Î³</sub>ë¥¼ ì—…ë°ì´íŠ¸ ì‹œì¼°ëŠ”ë°, ì´ ë…¼ë¬¸ì—ì„œëŠ” G(Z<sub>Î³</sub>)ì™€ ë§¤ì¹˜ì‹œí‚¤ê¸°ìœ„í•´ì„œ Z<sub>Î³</sub>ë¥¼ ì—…ë°ì´íŠ¸ ì‹œí‚´.  ì´ ë°©ë²•ì€ feature matching techniqueì—ì„œ ì˜ê°ì„ ì–»ì—ˆëŠ”ë°, ì´ëŠ” Dë¶€ë¶„ì—ì„œì˜ overtrainingìœ¼ë¡œ ë°œìƒí•˜ëŠ” GANì˜ instabilityì„ ë‹¤ë£¸.  ê¸°ì¡´ì— Dì˜ outputì„ ê·¹ëŒ€í™”ì‹œì¼œ Gì˜ parametersë¥¼ ì˜µí‹°ë§ˆì´ì§•ì‹œì¼°ë˜ ê²ƒì— ë°˜í•´, ì—¬ê¸°ì„œëŠ” **Gê°€ training dataì™€ ê°€ì¥ ë¹„ìŠ·í•œ statisticsë¥¼ ê°–ëŠ” ë°ì´í„°ë¥¼ ìƒì„±í•´ë‚´ë„ë¡ forceí•¨**. ì¦‰, Gë¶€ë¶„ì— íƒ€ê²Ÿì´ ë§ì¶°ì§€ê²Œ ë¨. 
- we do not adapt the training objective of the generator during adversarial training, but instead use the idea of feature matching to improve the mapping to the latent space. 
- Instead of using the scalar output of the discriminator for computing the discrimination loss, we propose to use a richer intermediate feature representation of the discriminator and define the discrimination loss:
L<sub>D</sub>(Z<sub>Î³</sub>) = Î£ |f(x)-f(G(Z<sub>Î³</sub>))|

> :warning: the output of an intermediate layer f(.) of the discriminator is used to specify the statistics of an input image. Based on this new loss term, the adaptation of the coordinates of z does not only rely on a hard decision of the trained discriminator, whether or not a generated image G(z<sub>Î³</sub>) fits the learned distribution of normal images, but instead takes the rich information of the feature representation, which is learned by the discriminator during adversarial trainning, into account. In this sense our approach utilizes the trained discriminator not as classifier but as a feature extractor. 


- latent spaceì— ë§µí•‘í•˜ê¸° ìœ„í•´, overall loss ëŠ” (weighted sumì— ì˜í•´ ì •ì˜)
L(Z<sub>Î³</sub>) = (1-Î»)L<sub>R</sub>(Z<sub>Î³</sub>) + Î»L<sub>D</sub>(Z<sub>Î³</sub>)
ì—¬ê¸°ì„œ Gì™€ Dì˜ trained paramtersëŠ” fixedë˜ì–´ ìˆê³ , zë§Œ backpropagationì— ì˜í•´ì„œ adaptë¨.

#### 2.3 Detection of anomalies
ì—¬ê¸°ì„œëŠ” anomaly score, A(x)ì´ìš©í•´ì„œ ì´ìƒì„ ë°œê²¬/íƒì§€í•¨. 
- **anomaly score, A(x)** : express the fit of a query image x to the model of normal images, can be directly derived from the mapping loss function.
A(x) = (1-Î»)R(x) + Î»D(x)
where, R(x) : residual score, residual lossê°€ ë§ˆì§€ë§‰ (Î“<sup>th</sup>)ì—ì„œì˜ L<sub>R</sub>(Z<sub>Î“</sub>)
       D(x) : discrimination score, discrimination lossê°€ ë§ˆì§€ë§‰ (Î“<sup>th</sup>)ì—ì„œì˜ L<sub>D</sub>(Z<sub>Î“</sub>)
- anomaly scoreì— ë”°ë¼ì„œ normal ê³¼ anomalë¥¼ êµ¬ë¶„í•˜ëŠ”ë°, 
  large anomaly score : anomalous images 
  small anomaly score : training ê³¼ êµ‰ì¥íˆ ìœ ì‚¬í•œ images, ì¦‰ normal imagesì˜ë¯¸
- **residual image, X<sub>R</sub> = |x-G(Z<sub>Î“</sub>)|** : identification of anomalous regions within an image (ì´ë¯¸ì§€ ì•ˆì—ì„œ ì´ìƒë¶€ë¶„ì„ ì°¾ëŠ” ê²ƒ) 
- ì¶”ê°€ì ìœ¼ë¡œ, **reference anomaly score, A'(x) = (1-Î»)R(x) + Î»D'(x)** where, reference discrimination score D'(x) = L<sub>D'</sub>(Z<sub>Î³</sub>)

### :seedling: Chap.3 Experiments
(Data, Data selection and preprocessing, Evaluation, Implementation details, )

- total volume resolution : 496 x 512 x 49 voxels (in x,y, and z dir)
- train : 270 clinical OCT volumes of healthy subjects
- test : 10 additional healthy cases + 10 pathological cases 
- preprocess : gray values were normalized to range from -1 to 1 
- (ì´í•˜ìƒëµ)

**Evaluation**
- (1) (ì§ˆì ) We explored qualitatively whether the model can generate realistic images. This assessment was performed on image patches of healthy cases extracted from the training set or test set and on images of diseased cases extracted from the test set.
- (2) (ì–‘ì ) We evaluated quantitatively the anomaly detection accuracy of our approach on images extracted from the annotated test set.We based the anomaly detection on the **anomaly score A(x) or only on one of both components, on the residual score R(x) or on the discrimination score D(x)** and report **receiver operating characteristic (ROC) curves of the corresponding anomaly detection performance on image level**. Based on our proposed anomaly score A(x), we evaluated qualitatively the segmentation performance and if additional anomalies were identified.
â†’ ROC ê³¡ì„  (ìˆ˜ì‹ ì ì¡°ì‘ íŠ¹ì„±) : íŠ¸ë ˆì´ë“œì˜¤í”„ ê´€ê³„ë¥¼ í‘œí˜„í•˜ê¸° ìœ„í•œ ì§€í‘œë¡œ xì¶•ì˜ íŠ¹ì´ë„ì— ëŒ€í•œ yì¶•ì˜ ì¬í˜„ìœ¨ (ë¯¼ê°ë„)ë¥¼ í‘œì‹œ.  
- (3) To provide more details of individual components' roles, and the gain by the proposed approach, we evaluated the effect on the anomaly detection performance, **when for manifold learning the adversarial training is not performed with a DCGAN but with an adversarial convolutional autoencoder (aCAE)** [16], while leaving the definition of the anomaly score unchanged. **An aCAE also implements a discriminator but replaces the generator by an encoder-decoder pipeline.** The depth of the components of the trained aCAE was comparable to the depth of our adversarial model. As a second alternative approach, denoted as GANR, we evaluated the anomaly detection performance, when the reference anomaly score A'(x), or the reference discrimination score D'(x) were utilized for anomaly scoring and the corresponding losses were used for the mapping from image space to latent space, while the pre-trained GAN parameters of the AnoGAN were used. We report ROC curves for both alternative approaches. Furthermore, we calculated sensitivity, specificity, precision, and recall at the optimal cut-off point on the ROC curves, identified through the Youden's index and report results for the AnoGan and for both alternative approaches.

**Implementation details**
- DCGAN architecture w/ images of sizes 64 x 64 pixels
- Generator: 4 fractionally strided convolution layers 
- Discriminator : 4 convolution layers  
- filters : 5x5 
- gray-scale images
- channels : 512-256-128-64
- epochs : 20
- Adam stochastic optimizer
- 500 backpropagation steps for the mapping of new images to the latent space
- Î» = 0.1
- python 2.7, tensorflow, titan X graphics processing unit using CUDA 8/0
#### 3.1 Results
demonstrate the generative capavility of the DCGAN and the appropriateness of our proposed mapping and scoring approach for anomaly detection
**Can the model generate realistic images?**
- normal images : ì˜ ìƒì„±í•´ëƒ„
- anomalous images : the pairs of input images and generated images show obvious intensity or textural differences. The t-SNE embedding of normal and anomalous images in the feature representation of the last convolution layer of the discriminator that is utilized in the **discrimination loss**, illustrates the usability of the discriminator's features for anomaly detection and suggests that our AnoGAN learns a mearniful manifold of normal anatomical variability.

**Can the model detect anomalies?**
Fig. 4
**How does the model compare to other approaches?**
- GAN<sub>R</sub>, aCAE, AnoGAN
- Although aCAEs simultaneously yield a generative model and a direct mapping to the latent space, which is advantageous in terms of runtimes during testing, this model showed worse performance on the anomaly detection task compared to the AnoGAN. It turned out that aCAEs tend to over-adapt on anomalous images.
- Nevertheless, according to the AUC, computed based on the anomaly score, the AnoGAN and the GANR show comparable results (Figure 4(a)). This has to be attributed to the good performance of the residual score R(x). A good anomaly detection performance (cf. PD in Figure 4(a) and Table 1) can be obtained when the mapping to the latent space is skipped and a binary decision is derived from the discriminator output, conditioned directly on the query image.
Table 1 


### :seedling: Chap.4 Conclusion 
- enable the identification of anomalies on unseen data based on **unsupervised training of a model on healthy data**.
- be able to detect **different known anomalies (retinal fulid, HRF)**.
- be expected to be capable to discover **novel anomalies**
- (discovering anomalies at scale) enables the mining of data for marker candidates subject to further verification. 


### ğŸ”‹ code 
check : https://github.com/seungjunlee96/AnoGAN-pytorch
